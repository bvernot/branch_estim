ggplot(dt.sed.og[, .(p = sum(mh)/.N, .N), f_mh], aes(x=f_mh, y=p, size=N)) + geom_point()
?q
a
complete.cases(a)
fg
source('~/GoogleDrive/branch_point_esimates/R/estim_branchpoints_from_sims.R', echo=TRUE)
?parser$add_argument
?add_argument
??add_argument
?argparse::add_argument
??argparse::add_argument
# install.packages('R.utils')
# install.packages('argparse')
library(argparse)
?argparse::add_argument
??argparse::add_argument
parser$add_argument("-sites", "--sites", required=F, default = 'all', nargs='+', dest = 'site_cat',
help='Site categories to use. Can be a list. Options: all, poly_archaic, poly_neand, mh_seg_arc_fixed0')
# create parser object
parser <- ArgumentParser()
parser$add_argument("-sites", "--sites", required=F, default = 'all', nargs='+', dest = 'site_cat',
help='Site categories to use. Can be a list. Options: all, poly_archaic, poly_neand, mh_seg_arc_fixed0')
dump_and_quit <- function() {
## Save debugging info to file last.dump.rda
traceback()
## Quit R with error status
q(status = 1)
}
options(error = dump_and_quit, width=200)
# install.packages('R.utils')
# install.packages('argparse')
library(argparse)
library(here)
# options(error=recover)
# options(error=NULL)
# create parser object
parser <- ArgumentParser()
parser$add_argument("-v", "--verbose", action="store_true", default=F,
help="Print extra output")
parser$add_argument("-nc", "--ncores", type='integer', default=1,
help="Number of cores to use. [not currently used?]")
parser$add_argument("-sims", "--sims.dat", required = T,
help="")
parser$add_argument("-gts", "--simple-gts", required=T,
help="all_simple_gts.tsv.gz")
parser$add_argument("-table", "--output-table", required=F,
help="Save the results to <output-table> in tsv form.")
parser$add_argument("-true-branch", "--true-branch", required=F, default='NA',
help="The simulated branch, used in plots and tables.")
parser$add_argument("-true-branchtime", "--true-branchtime", required=F, default='NA',
help="The simulated branchtime, used in plots and tables.")
parser$add_argument("-set-mh-contam", "--set-mh-contam", required=F, default='estim',
help="If provided, constrain MH contamination to this value. [currently only works with a single value, across all RG]")
parser$add_argument("-set-faunal-prop", "--set-faunal-prop", required=F, default='estim',
help="If provided, constrain faunal proportion to this value. [currently only works with a single value, across all RG]")
parser$add_argument("-branch", "--branch", required=F, default=NULL,
help="Only run the EM on a single branch. e.g. --branch v")
parser$add_argument("-sample-mh", "--sample-mh-from-freqs", default=F, action='store_true',
help="Sample the mh 'contamination' from f_mh frequencies rather than a separate column mh")
parser$add_argument("-f-mh", "--f-mh", default='f_mh',
help="Use this column ID for modern human allele frquencies.  Default is f_mh")
parser$add_argument("-libs", "--libs", required=F,
help="One or more libraries to group together. The EM still treats them as separate read groups.  To treat these as a single read group, use --merge-libs.")
parser$add_argument("-merge-libs", "--merge-libs", action="store_true", default=F,
help="Merge all requested libraries into a single read group (or entire file, if --libs not given).")
parser$add_argument("-tag", "--tag", required=F, default='none',
help="One (or more, in the future) tags for this analysis.")
parser$add_argument("-niter", "--num-iters", type='integer', default=100,
help="Number of EM iterations")
parser$add_argument("-n-qc1", "--n-qc1", type='integer', default=1000,
help="Artificially add N QC sites that are DERIVED in all hominins. These are used for calculating faunal proportions, and have to be artificially added to simulated data.")
parser$add_argument("-n-qc0", "--n-qc0", type='integer', default=0,
help="Artificially add N QC sites that are ANCESTRAL in all hominins. These are not present/useful in real data, so this should mostly be used for debugging.")
parser$add_argument("-downsample", "--downsample", type='integer', default=0,
help="Downsample data to N reads. This samples the entire dataset, so e.g. if originally each read group was 25% of the data, these proportions may change.")
parser$add_argument("-add-contam", "--add-contam", type='double', default=0, nargs='+',
help="Artificially add contamination in these proportions")
parser$add_argument("-add-faunal", "--add-faunal", type='double', default=0, nargs='+',
help='Artificially add faunal "contamination" in these proportions')
parser$add_argument("-rg-props", "--rg-props", type='double', default=1, nargs='+',
help="Randomly split the simulations into read groups with these proportions")
parser$add_argument("-sites", "--sites", required=F, default = 'all', nargs='+', dest = 'site_cat',
help='Site categories to use. Can be a list. Options: all, poly_archaic, poly_neand, mh_seg_arc_fixed0')
parser$add_argument("-method", "--sim-method", required=F, default = 'simple',
help='Site categories to use [not currently implemented]')
parser$add_argument("-script-path", "--script-path", required=F, default = NULL,
help='A hack to let R find the path for scripts to source.')
parser$add_argument("-prefix", "--prefix", required=T,
help="Prefix for output files.")
if (interactive()) {
# args <- parser$parse_args(strsplit('-gts ~/Downloads/all_simple_gts.tsv.gz --sims ~/Documents/soil_dna_capture/sims.dat.RDS -libs A17273 --prefix what -nc 2', split = ' ')[[1]])
# args <- parser$parse_args(strsplit('-gts "~/GoogleDrive/branch_point_estimates/all_simple_gts.tsv.gz" --sims "~/GoogleDrive/branch_point_estimates/sims.dat.RDS" -libs A20281 --prefix what -nc 2 -sites all -tag hey', split = ' ')[[1]])
args <- parser$parse_args(strsplit('-gts ~/Downloads/all_simple_gts.small.tsv.gz --sims ~/Downloads/sims.dat.RDS -libs A20281 --prefix what -nc 2 -sites all -tag hey', split = ' ')[[1]])
args <- parser$parse_args(strsplit('-gts ~/Downloads/hey.gt.txt.gz --sims ~/Downloads/sims.dat.RDS --prefix what -nc 2 -sites all -tag hey', split = ' ')[[1]])
args <- parser$parse_args(strsplit('-gts ~/Downloads/test_sims_v_0.7601_ALL.gt.txt.gz --sims ~/Downloads/sims.dat.RDS --prefix what -nc 2 -sites all -tag hey', split = ' ')[[1]])
args <- parser$parse_args(strsplit('-gts ~/GoogleDrive/branch_point_esimates/data/test_sims_v_0.7601_ALL.gt.txt.gz --sims ~/GoogleDrive/branch_point_esimates/data/sims.dat.RDS --prefix what -nc 2 -sites all -tag hey --sim-method simple --libs sims009.v.0.7601.1 --rg-props .2 .8 --add-contam 0 .1 --downsample 10000 --n-qc1 1000 --branch v -niter 5 -table hey.txt', split = ' ')[[1]])
# args <- parser$parse_args(strsplit('-gts ~/GoogleDrive/branch_point_esimates/data/ --sims ~/GoogleDrive/branch_point_esimates/data/sims.dat.RDS --prefix what -nc 2 -sites all -tag hey --sim-method simple --libs sims009.v.0.7601.1 --rg-props .2 .8 --add-contam 0 .1 --downsample 10000 --n-qc1 1000 --branch v -niter 5 -table hey.txt', split = ' ')[[1]])
# args <- parser$parse_args(strsplit('--splits ~/Documents/index_cross_contam/data/ludovic/splitstats_ludovic_orlando_001.myformat3.txt -nhits 100 --prefix splitstats_ludovic_orlando_001 -nc 2 --sources 150', split = ' ')[[1]])
} else {
args <- parser$parse_args()
}
if (length(args$add_contam) == 1) args$add_contam <- rep(args$add_contam, length(args$rg_props))
if (length(args$add_faunal) == 1) args$add_faunal <- rep(args$add_faunal, length(args$rg_props))
if ( length(args$rg_props) != length(args$add_contam) || length(args$rg_props) != length(args$add_faunal) ) {
cat('Must provide contamination and faunal proportions for each read group:\n')
cat('RG:', args$rg_props, '\n')
cat('contam:', args$add_contam, '\n')
cat('faunal:', args$add_faunal, '\n')
q(save='no', status=1)
}
if (is.null(args$script_path)) {
source(here('R/estim_branchpoints_fns.R'))
} else {
source(paste0(args$script_path, '/estim_branchpoints_fns.R'))
}
# registerDoParallel(cores=args$ncores)
# getDoParWorkers()
# sims.dat <- readRDS('~/Google Drive/branch_point_esimates/sims.dat.RDS')
sims.dat <- readRDS(args$sims.dat)
## this 0.004 doesn't matter here, because it's modified in a different function!
sims.dat <- add_linear_p_given_b_t_arcs(sims.dat, fixed_anc_p = 0.004)
# dt.sed.og <- fread('~/Google Drive/branch_point_esimates/all_simple_gts.tsv.gz')
# dt.sed.og <- fread('~/Downloads/all_simple_gts.tsv.gz')
cat('Reading genotypes..', args$simple_gts, '\n')
dt.sed.og <- fread(args$simple_gts)
cat('  Read:', dt.sed.og[, .N], 'sites\n')
cat('  Libraries in file:', dt.sed.og[, unique(lib)], '\n')
####
## confirm that all of the correct columns are present
setnames(dt.sed.og, args$f_mh, 'f_mh')
req_columns <- c('sed_gt', 'v_gt', 'c_gt', 'a_gt', 'd_gt', 'f_mh', 'lib')
if (sum(!req_columns %in% colnames(dt.sed.og)) > 0) {
cat('Not all required columns are present:\n')
cat('Required: ', req_columns, '\n')
cat('Missing: ', req_columns[!req_columns %in% colnames(dt.sed.og)], '\n')
stop()
}
## if there's no mh column, then sample from f_mh
## anyway, we require complete.cases for f_mh
dt.sed.og <- dt.sed.og[!is.na(dt.sed.og$f_mh)]
if (!'mh' %in% colnames(dt.sed.og) || args$sample_mh_from_freqs)
dt.sed.og$mh <- sapply(dt.sed.og[, f_mh], function(f_mh) sample(0:1, 1, prob = c(1-f_mh,f_mh)))
# ggplot(dt.sed.og[, .(p = sum(mh)/.N, .N), f_mh], aes(x=f_mh, y=p, size=N)) + geom_point()
## ISSUE - could move this to sed_EM? but probably best to remove unexpected columns now
dt.sed.og <- dt.sed.og[, .(sed_gt, v_gt, c_gt, a_gt, d_gt, f_mh, mh, lib)]
cat('Filtering rows with NA in required columns:', sum(!complete.cases(dt.sed.og)), 'sites\n')
dt.sed.og <- dt.sed.og[complete.cases(dt.sed.og)]
cat('  Remaining:', dt.sed.og[, .N], 'sites\n')
if (!is.null(args$libs)) {
if (sum(!args$libs %in% dt.sed.og[, unique(lib)]) > 0) {
cat('Requested library is not in dataset:', args$libs[!args$libs %in% dt.sed.og[, unique(lib)]], '\n')
q(save='no', status=1)
}
cat('Filtering requested libraries: ', args$libs, '\n')
dt.sed <- dt.sed.og[lib %in% args$libs]
cat('Keeping: ', dt.sed[, .N], 'sites\n')
} else {
## not really necessary, takes up a lot more space...
dt.sed <- data.table(dt.sed.og)
cat('Using all libraries\n')
}
if (args$merge_libs) {
dt.sed[, lib := 'merged_libs']
cat('Merging libraries\n')
}
# ## set up simulated data, because I didn't previously fill this in
# dt.sed[, lib := 'sim009']
# setnames(dt.sed, c('sed', 'mh_f'), c('sed_gt', 'f_mh'))
if ('all' %in% args$site_cat || 'poly_arc' %in% args$site_cat) {
dt.sed.poly.full <- dt.sed[!(v_gt == c_gt & v_gt == a_gt & v_gt == d_gt)]
cat('Polymorphic in archaic: ', dt.sed.poly.full[, .N], 'sites\n')
} else if ('poly_neand' %in% args$site_cat) {
dt.sed.poly.full <- dt.sed[!(v_gt == c_gt & v_gt == a_gt)]
cat('Polymorphic in neands: ', dt.sed.poly.full[, .N], 'sites\n')
} else {
dt.sed.poly.full <- data.table()
}
# dt.sed.poly.full[, deam53 := rep(c(T,T,F,F,F), length.out = .N)]
# dt.sed.poly.full[, f_mh := f_mh / 99]
# dt.sed.poly.full[, pos := NULL]
if ('all' %in% args$site_cat || 'mh_seg_arc_fixed0' %in% args$site_cat) {
dt.sed.mh.full <- dt.sed[v_gt == c_gt & v_gt == a_gt & v_gt == d_gt & v_gt == 0 & f_mh > 0]
cat('Ancestral in archaics, seg in MH: ', dt.sed.mh.full[, .N], 'sites\n')
} else {
dt.sed.mh.full <- data.table()
}
# dt.sed.mh.full[, deam53 := rep(c(T,T,F,F,F), length.out = .N)]
# dt.sed.mh.full[, f_mh := f_mh / 99]
# dt.sed.mh.full[, pos := NULL]
## simulate QC sites - but should also save QC sites in real data [code to do this is in an older scratch file]
dt.sed.qc.full <- foreach(my.lib = dt.sed.poly.full[, unique(lib)], .combine = rbind) %do% {
## just duplicate the first row of dt.sed.poly.full the correct number of times
dt.sed.qc.full <- dt.sed.poly.full[lib == my.lib][rep(1, args$n_qc0 + args$n_qc1)]
qc_fill_freq_or_hap <- c(rep(0,args$n_qc0), rep(1,args$n_qc1))
qc_fill_gt <- c(rep(0,args$n_qc0), rep(2,args$n_qc1))
dt.sed.qc.full[, f_mh := qc_fill_freq_or_hap]
dt.sed.qc.full[, mh := qc_fill_freq_or_hap]
dt.sed.qc.full[, v_gt := qc_fill_gt]
dt.sed.qc.full[, c_gt := qc_fill_gt]
dt.sed.qc.full[, a_gt := qc_fill_gt]
dt.sed.qc.full[, d_gt := qc_fill_gt]
dt.sed.qc.full[, sed_gt := qc_fill_freq_or_hap]
dt.sed.qc.full
}
## downsample reads if necessary
## not really necessary to make new data.tables, takes up a lot more space...
dt.sed.poly <- data.table(dt.sed.poly.full)
dt.sed.mh <- data.table(dt.sed.mh.full)
dt.sed.qc <- data.table(dt.sed.qc.full)
nreads <- dt.sed.poly[, .N] + dt.sed.mh[, .N]
if (args$downsample > 0) dt.sed.poly <- dt.sed.poly[sample(.N, .N / nreads * args$downsample)]
dt.sed.mh <- data.table(dt.sed.mh.full)
if (args$downsample > 0) dt.sed.mh <- dt.sed.mh[sample(.N, .N / nreads * args$downsample)]
dt.sed.analysis <- rbind(dt.sed.mh, dt.sed.qc, dt.sed.poly)
args$nreads <- dt.sed.poly[, .N] + dt.sed.mh[, .N] + dt.sed.qc[, .N]
if (args$downsample > 0) cat('Downsample to requested number of sites: ', args$nreads, 'sites\n')
# create parser object
parser <- ArgumentParser()
parser$add_argument("-v", "--verbose", action="store_true", default=F,
help="Print extra output")
parser$add_argument("-nc", "--ncores", type='integer', default=1,
help="Number of cores to use. [not currently used?]")
parser$add_argument("-sims", "--sims.dat", required = T,
help="")
parser$add_argument("-gts", "--simple-gts", required=T,
help="all_simple_gts.tsv.gz")
parser$add_argument("-libs", "--libs", required=F,
help="One or more libraries to group together. The EM still treats them as separate read groups.  To treat these as a single read group, use --merge-libs.")
parser$add_argument("-merge-libs", "--merge-libs", action="store_true", default=F,
help="Merge all requested libraries into a single read group (or entire file, if --libs not given).")
parser$add_argument("-table", "--output-table", required=F,
help="Save the results to <output-table> in tsv form.  Also saves an RDS of the em results.")
parser$add_argument("-debug-gts", "--debug-gts-at-time", required=F, type='double',
help="Given a branch and a branch time, report expected and observed p(der) for each genotype category. Requires --branch also.")
parser$add_argument("-branch", "--branch", required=F, default=NULL,
help="Only run the EM on a single branch. e.g. --branch v.  Required for --debug-gts-at-time.")
parser$add_argument("-true-branch", "--true-branch", required=F, default='NA',
help="The simulated branch, used in plots and tables.")
parser$add_argument("-true-branchtime", "--true-branchtime", required=F, default='NA',
help="The simulated branchtime, used in plots and tables.")
parser$add_argument("-set-mh-contam", "--set-mh-contam", required=F, default='estim',
help="If provided, constrain MH contamination to this value. [currently only works with a single value, across all RG]")
parser$add_argument("-set-faunal-prop", "--set-faunal-prop", required=F, default='estim',
help="If provided, constrain faunal proportion to this value. [currently only works with a single value, across all RG]")
parser$add_argument("-sample-mh", "--sample-mh-from-freqs", default=F, action='store_true',
help="Sample the mh 'contamination' from f_mh frequencies rather than a separate column mh")
parser$add_argument("-f-mh", "--f-mh", default='f_mh',
help="Use this column ID for modern human allele frquencies.  Default is f_mh")
parser$add_argument("-tag", "--tag", required=F, default='none',
help="One (or more, in the future) tags for this analysis.")
parser$add_argument("-niter", "--num-iters", type='integer', default=100,
help="Number of EM iterations")
parser$add_argument("-n-qc1", "--n-qc1", type='integer', default=1000,
help="Artificially add N QC sites that are DERIVED in all hominins. These are used for calculating faunal proportions, and have to be artificially added to simulated data.")
parser$add_argument("-n-qc0", "--n-qc0", type='integer', default=0,
help="Artificially add N QC sites that are ANCESTRAL in all hominins. These are not present/useful in real data, so this should mostly be used for debugging.")
parser$add_argument("-downsample", "--downsample", type='integer', default=0,
help="Downsample data to N reads. This samples the entire dataset, so e.g. if originally each read group was 25% of the data, these proportions may change.")
parser$add_argument("-add-contam", "--add-contam", type='double', default=0, nargs='+',
help="Artificially add contamination in these proportions")
parser$add_argument("-add-faunal", "--add-faunal", type='double', default=0, nargs='+',
help='Artificially add faunal "contamination" in these proportions')
parser$add_argument("-rg-props", "--rg-props", type='double', default=1, nargs='+',
help="Randomly split the simulations into read groups with these proportions")
parser$add_argument("-sites", "--sites", required=F, default = 'all', nargs='+', dest = 'site_cat',
help='Site categories to use. Can be a list. Options: all, poly_archaic, poly_neand, mh_seg_arc_fixed0')
parser$add_argument("-method", "--sim-method", required=F, default = 'simple',
help='Site categories to use [not currently implemented]')
parser$add_argument("-script-path", "--script-path", required=F, default = NULL,
help='A hack to let R find the path for scripts to source.')
parser$add_argument("-prefix", "--prefix", required=T,
help="Prefix for output files.")
args <- parser$parse_args(strsplit('-gts ~/GoogleDrive/branch_point_esimates/data/test_sims_v_0.7601_ALL.gt.txt.gz --sims ~/GoogleDrive/branch_point_esimates/data/sims.dat.RDS --prefix what -nc 2 -sites all -tag hey --sim-method simple --libs sims009.v.0.7601.1 --rg-props .2 .8 --add-contam 0 .1 --downsample 10000 --n-qc1 1000 --branch v -niter 5 -table hey.txt', split = ' ')[[1]])
sims.dat$dt.sims.p
sims.dat
sims.dat$dt.simple_p_given_b_t_arcs
all.gt <- sims.dat$dt.simple_p_given_b_t_arcs[branch == args$branch]
all.gt
gt.idx = 25
sims.dat$simple_p_given_b_t_arcs(args$branch, args$debug_gts_at_time,
my.gt = all.gt[gt.idx, .(v_gt, c_gt, a_gt, d_gt)])
source('~/GoogleDrive/branch_point_esimates/R/estim_branchpoints_from_sims.R', echo=TRUE)
sims.dat$simple_p_given_b_t_arcs
dump_and_quit <- function() {
## Save debugging info to file last.dump.rda
traceback()
## Quit R with error status
q(status = 1)
}
options(error = dump_and_quit, width=200)
# install.packages('R.utils')
# install.packages('argparse')
library(argparse)
library(here)
# options(error=recover)
# options(error=NULL)
# create parser object
parser <- ArgumentParser()
parser$add_argument("-v", "--verbose", action="store_true", default=F,
help="Print extra output")
parser$add_argument("-nc", "--ncores", type='integer', default=1,
help="Number of cores to use. [not currently used?]")
parser$add_argument("-sims", "--sims.dat", required = T,
help="")
parser$add_argument("-gts", "--simple-gts", required=T,
help="all_simple_gts.tsv.gz")
parser$add_argument("-libs", "--libs", required=F,
help="One or more libraries to group together. The EM still treats them as separate read groups.  To treat these as a single read group, use --merge-libs.")
parser$add_argument("-merge-libs", "--merge-libs", action="store_true", default=F,
help="Merge all requested libraries into a single read group (or entire file, if --libs not given).")
parser$add_argument("-table", "--output-table", required=F,
help="Save the results to <output-table> in tsv form.  Also saves an RDS of the em results.")
parser$add_argument("-debug-gts", "--debug-gts-at-time", required=F, type='double',
help="Given a branch and a branch time, report expected and observed p(der) for each genotype category. Requires --branch also.")
parser$add_argument("-branch", "--branch", required=F, default=NULL,
help="Only run the EM on a single branch. e.g. --branch v.  Required for --debug-gts-at-time.")
parser$add_argument("-true-branch", "--true-branch", required=F, default='NA',
help="The simulated branch, used in plots and tables.")
parser$add_argument("-true-branchtime", "--true-branchtime", required=F, default='NA',
help="The simulated branchtime, used in plots and tables.")
parser$add_argument("-set-mh-contam", "--set-mh-contam", required=F, default='estim',
help="If provided, constrain MH contamination to this value. [currently only works with a single value, across all RG]")
parser$add_argument("-set-faunal-prop", "--set-faunal-prop", required=F, default='estim',
help="If provided, constrain faunal proportion to this value. [currently only works with a single value, across all RG]")
parser$add_argument("-sample-mh", "--sample-mh-from-freqs", default=F, action='store_true',
help="Sample the mh 'contamination' from f_mh frequencies rather than a separate column mh")
parser$add_argument("-f-mh", "--f-mh", default='f_mh',
help="Use this column ID for modern human allele frquencies.  Default is f_mh")
parser$add_argument("-tag", "--tag", required=F, default='none',
help="One (or more, in the future) tags for this analysis.")
parser$add_argument("-niter", "--num-iters", type='integer', default=100,
help="Number of EM iterations")
parser$add_argument("-n-qc1", "--n-qc1", type='integer', default=1000,
help="Artificially add N QC sites that are DERIVED in all hominins. These are used for calculating faunal proportions, and have to be artificially added to simulated data.")
parser$add_argument("-n-qc0", "--n-qc0", type='integer', default=0,
help="Artificially add N QC sites that are ANCESTRAL in all hominins. These are not present/useful in real data, so this should mostly be used for debugging.")
parser$add_argument("-downsample", "--downsample", type='integer', default=0,
help="Downsample data to N reads. This samples the entire dataset, so e.g. if originally each read group was 25% of the data, these proportions may change.")
parser$add_argument("-add-contam", "--add-contam", type='double', default=0, nargs='+',
help="Artificially add contamination in these proportions")
parser$add_argument("-add-faunal", "--add-faunal", type='double', default=0, nargs='+',
help='Artificially add faunal "contamination" in these proportions')
parser$add_argument("-rg-props", "--rg-props", type='double', default=1, nargs='+',
help="Randomly split the simulations into read groups with these proportions")
parser$add_argument("-sites", "--sites", required=F, default = 'all', nargs='+', dest = 'site_cat',
help='Site categories to use. Can be a list. Options: all, poly_archaic, poly_neand, mh_seg_arc_fixed0')
parser$add_argument("-method", "--sim-method", required=F, default = 'simple',
help='Site categories to use [not currently implemented]')
parser$add_argument("-script-path", "--script-path", required=F, default = NULL,
help='A hack to let R find the path for scripts to source.')
parser$add_argument("-prefix", "--prefix", required=T,
help="Prefix for output files.")
if (interactive()) {
# args <- parser$parse_args(strsplit('-gts ~/Downloads/all_simple_gts.tsv.gz --sims ~/Documents/soil_dna_capture/sims.dat.RDS -libs A17273 --prefix what -nc 2', split = ' ')[[1]])
# args <- parser$parse_args(strsplit('-gts "~/GoogleDrive/branch_point_estimates/all_simple_gts.tsv.gz" --sims "~/GoogleDrive/branch_point_estimates/sims.dat.RDS" -libs A20281 --prefix what -nc 2 -sites all -tag hey', split = ' ')[[1]])
args <- parser$parse_args(strsplit('-gts ~/Downloads/all_simple_gts.small.tsv.gz --sims ~/Downloads/sims.dat.RDS -libs A20281 --prefix what -nc 2 -sites all -tag hey', split = ' ')[[1]])
args <- parser$parse_args(strsplit('-gts ~/Downloads/hey.gt.txt.gz --sims ~/Downloads/sims.dat.RDS --prefix what -nc 2 -sites all -tag hey', split = ' ')[[1]])
args <- parser$parse_args(strsplit('-gts ~/Downloads/test_sims_v_0.7601_ALL.gt.txt.gz --sims ~/Downloads/sims.dat.RDS --prefix what -nc 2 -sites all -tag hey', split = ' ')[[1]])
args <- parser$parse_args(strsplit('-gts ~/GoogleDrive/branch_point_esimates/data/test_sims_v_0.7601_ALL.gt.txt.gz --sims ~/GoogleDrive/branch_point_esimates/data/sims.dat.RDS --debug-gts-at-time 0.7601 --prefix what -nc 2 -sites all -tag hey --sim-method simple --libs sims009.v.0.7601.1 --rg-props .2 .8 --add-contam 0 .1 --downsample 10000 --n-qc1 1000 --branch v -niter 5 -table hey.txt', split = ' ')[[1]])
# args <- parser$parse_args(strsplit('-gts ~/GoogleDrive/branch_point_esimates/data/ --sims ~/GoogleDrive/branch_point_esimates/data/sims.dat.RDS --prefix what -nc 2 -sites all -tag hey --sim-method simple --libs sims009.v.0.7601.1 --rg-props .2 .8 --add-contam 0 .1 --downsample 10000 --n-qc1 1000 --branch v -niter 5 -table hey.txt', split = ' ')[[1]])
# args <- parser$parse_args(strsplit('--splits ~/Documents/index_cross_contam/data/ludovic/splitstats_ludovic_orlando_001.myformat3.txt -nhits 100 --prefix splitstats_ludovic_orlando_001 -nc 2 --sources 150', split = ' ')[[1]])
} else {
args <- parser$parse_args()
}
if (length(args$add_contam) == 1) args$add_contam <- rep(args$add_contam, length(args$rg_props))
if (length(args$add_faunal) == 1) args$add_faunal <- rep(args$add_faunal, length(args$rg_props))
if ( length(args$rg_props) != length(args$add_contam) || length(args$rg_props) != length(args$add_faunal) ) {
cat('Must provide contamination and faunal proportions for each read group:\n')
cat('RG:', args$rg_props, '\n')
cat('contam:', args$add_contam, '\n')
cat('faunal:', args$add_faunal, '\n')
q(save='no', status=1)
}
if (is.null(args$script_path)) {
source(here('R/estim_branchpoints_fns.R'))
} else {
source(paste0(args$script_path, '/estim_branchpoints_fns.R'))
}
# registerDoParallel(cores=args$ncores)
# getDoParWorkers()
# sims.dat <- readRDS('~/Google Drive/branch_point_esimates/sims.dat.RDS')
sims.dat <- readRDS(args$sims.dat)
## this 0.004 doesn't matter here, because it's modified in a different function!
sims.dat <- add_linear_p_given_b_t_arcs(sims.dat, fixed_anc_p = 0.004)
# dt.sed.og <- fread('~/Google Drive/branch_point_esimates/all_simple_gts.tsv.gz')
# dt.sed.og <- fread('~/Downloads/all_simple_gts.tsv.gz')
cat('Reading genotypes..', args$simple_gts, '\n')
dt.sed.og <- fread(args$simple_gts)
cat('  Read:', dt.sed.og[, .N], 'sites\n')
cat('  Libraries in file:', dt.sed.og[, unique(lib)], '\n')
####
## confirm that all of the correct columns are present
setnames(dt.sed.og, args$f_mh, 'f_mh')
req_columns <- c('sed_gt', 'v_gt', 'c_gt', 'a_gt', 'd_gt', 'f_mh', 'lib')
if (sum(!req_columns %in% colnames(dt.sed.og)) > 0) {
cat('Not all required columns are present:\n')
cat('Required: ', req_columns, '\n')
cat('Missing: ', req_columns[!req_columns %in% colnames(dt.sed.og)], '\n')
stop()
}
## if there's no mh column, then sample from f_mh
## anyway, we require complete.cases for f_mh
dt.sed.og <- dt.sed.og[!is.na(dt.sed.og$f_mh)]
if (!'mh' %in% colnames(dt.sed.og) || args$sample_mh_from_freqs)
dt.sed.og$mh <- sapply(dt.sed.og[, f_mh], function(f_mh) sample(0:1, 1, prob = c(1-f_mh,f_mh)))
# ggplot(dt.sed.og[, .(p = sum(mh)/.N, .N), f_mh], aes(x=f_mh, y=p, size=N)) + geom_point()
## ISSUE - could move this to sed_EM? but probably best to remove unexpected columns now
dt.sed.og <- dt.sed.og[, .(sed_gt, v_gt, c_gt, a_gt, d_gt, f_mh, mh, lib)]
cat('Filtering rows with NA in required columns:', sum(!complete.cases(dt.sed.og)), 'sites\n')
dt.sed.og <- dt.sed.og[complete.cases(dt.sed.og)]
cat('  Remaining:', dt.sed.og[, .N], 'sites\n')
if (!is.null(args$libs)) {
if (sum(!args$libs %in% dt.sed.og[, unique(lib)]) > 0) {
cat('Requested library is not in dataset:', args$libs[!args$libs %in% dt.sed.og[, unique(lib)]], '\n')
q(save='no', status=1)
}
cat('Filtering requested libraries: ', args$libs, '\n')
dt.sed <- dt.sed.og[lib %in% args$libs]
cat('Keeping: ', dt.sed[, .N], 'sites\n')
} else {
## not really necessary, takes up a lot more space...
dt.sed <- data.table(dt.sed.og)
cat('Using all libraries\n')
}
if (args$merge_libs) {
dt.sed[, lib := 'merged_libs']
cat('Merging libraries\n')
}
# ## set up simulated data, because I didn't previously fill this in
# dt.sed[, lib := 'sim009']
# setnames(dt.sed, c('sed', 'mh_f'), c('sed_gt', 'f_mh'))
if ('all' %in% args$site_cat || 'poly_arc' %in% args$site_cat) {
dt.sed.poly.full <- dt.sed[!(v_gt == c_gt & v_gt == a_gt & v_gt == d_gt)]
cat('Polymorphic in archaic: ', dt.sed.poly.full[, .N], 'sites\n')
} else if ('poly_neand' %in% args$site_cat) {
dt.sed.poly.full <- dt.sed[!(v_gt == c_gt & v_gt == a_gt)]
cat('Polymorphic in neands: ', dt.sed.poly.full[, .N], 'sites\n')
} else {
dt.sed.poly.full <- data.table()
}
# dt.sed.poly.full[, deam53 := rep(c(T,T,F,F,F), length.out = .N)]
# dt.sed.poly.full[, f_mh := f_mh / 99]
# dt.sed.poly.full[, pos := NULL]
if ('all' %in% args$site_cat || 'mh_seg_arc_fixed0' %in% args$site_cat) {
dt.sed.mh.full <- dt.sed[v_gt == c_gt & v_gt == a_gt & v_gt == d_gt & v_gt == 0 & f_mh > 0]
cat('Ancestral in archaics, seg in MH: ', dt.sed.mh.full[, .N], 'sites\n')
} else {
dt.sed.mh.full <- data.table()
}
# dt.sed.mh.full[, deam53 := rep(c(T,T,F,F,F), length.out = .N)]
# dt.sed.mh.full[, f_mh := f_mh / 99]
# dt.sed.mh.full[, pos := NULL]
## simulate QC sites - but should also save QC sites in real data [code to do this is in an older scratch file]
dt.sed.qc.full <- foreach(my.lib = dt.sed.poly.full[, unique(lib)], .combine = rbind) %do% {
## just duplicate the first row of dt.sed.poly.full the correct number of times
dt.sed.qc.full <- dt.sed.poly.full[lib == my.lib][rep(1, args$n_qc0 + args$n_qc1)]
qc_fill_freq_or_hap <- c(rep(0,args$n_qc0), rep(1,args$n_qc1))
qc_fill_gt <- c(rep(0,args$n_qc0), rep(2,args$n_qc1))
dt.sed.qc.full[, f_mh := qc_fill_freq_or_hap]
dt.sed.qc.full[, mh := qc_fill_freq_or_hap]
dt.sed.qc.full[, v_gt := qc_fill_gt]
dt.sed.qc.full[, c_gt := qc_fill_gt]
dt.sed.qc.full[, a_gt := qc_fill_gt]
dt.sed.qc.full[, d_gt := qc_fill_gt]
dt.sed.qc.full[, sed_gt := qc_fill_freq_or_hap]
dt.sed.qc.full
}
## downsample reads if necessary
## not really necessary to make new data.tables, takes up a lot more space...
dt.sed.poly <- data.table(dt.sed.poly.full)
dt.sed.mh <- data.table(dt.sed.mh.full)
dt.sed.qc <- data.table(dt.sed.qc.full)
nreads <- dt.sed.poly[, .N] + dt.sed.mh[, .N]
if (args$downsample > 0) dt.sed.poly <- dt.sed.poly[sample(.N, .N / nreads * args$downsample)]
dt.sed.mh <- data.table(dt.sed.mh.full)
if (args$downsample > 0) dt.sed.mh <- dt.sed.mh[sample(.N, .N / nreads * args$downsample)]
dt.sed.analysis <- rbind(dt.sed.mh, dt.sed.qc, dt.sed.poly)
args$nreads <- dt.sed.poly[, .N] + dt.sed.mh[, .N] + dt.sed.qc[, .N]
if (args$downsample > 0) cat('Downsample to requested number of sites: ', args$nreads, 'sites\n')
####################
## create read groups
## make sure that proportions sum to 1
args$rg_props <- args$rg_props / sum(args$rg_props)
## ISSUE - this doesn't work correctly if there are multple libraries and multiple read groups,
## because you end up with more read groups than contam proportions, etc
dt.sed.analysis[, rg := paste0(lib, '_rg_', sample(1:length(args$rg_props), .N, replace = T, prob = args$rg_props))]
####################
## simulate contamination
all_rg = dt.sed.analysis[, unique(rg)]
for (my_rg.idx in 1:length(all_rg)) {
my_rg = all_rg[my_rg.idx]
my_rg.contam = args$add_contam[my_rg.idx]
my_rg.contam.sites = dt.sed.analysis[, rg == my_rg]
sum(my_rg.contam.sites)
sum(my_rg.contam.sites) / length(my_rg.contam.sites)
my_rg.contam.sites[my_rg.contam.sites] <- sample(c(T,F), sum(my_rg.contam.sites), replace = T,
prob = c(my_rg.contam,1-my_rg.contam))
sum(my_rg.contam.sites)
sum(my_rg.contam.sites) / length(my_rg.contam.sites)
sum(my_rg.contam.sites) / dt.sed.analysis[rg == my_rg, .N]
dt.sed.analysis[my_rg.contam.sites, sed_gt := mh]
}
sims.dat$simple_p_given_b_t_arcs
all.gt <- sims.dat$dt.simple_p_given_b_t_arcs[branch == args$branch]
for (gt.idx in 1:nrow(all.gt)) {
sims.dat$simple_p_given_b_t_arcs(args$branch, args$debug_gts_at_time,
my.gt = all.gt[gt.idx, .(v_gt, c_gt, a_gt, d_gt)],
sims.dat = sims.dat)
}
this.gt <- all.gt[gt.idx, .(v_gt, c_gt, a_gt, d_gt)]
this.gt
dt.sed.analysis[this.gt]
